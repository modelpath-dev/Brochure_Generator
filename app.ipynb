{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json \n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key wrking fine\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key wrking fine\")\n",
    "else:\n",
    "    print(\"Check api key again\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "header={\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self,url):\n",
    "        self.url=url\n",
    "        response=requests.get(url, headers=header)\n",
    "        self.body=response.content\n",
    "        soup=BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title=soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for faaltu in soup.body(['script', 'style','img','input']):\n",
    "                faaltu.decompose()\n",
    "            self.text=soup.body.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            self.text=\"\"\n",
    "        links=[link.get('href') for link in soup.find_all('a')]\n",
    "        self.links=[link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=\"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "\n",
    "system_prompt+='You should respond in JSON as in this example:'\n",
    "system_prompt+=\"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(website):\n",
    "    user_prompt=f'Here is the list of links on the website of {website.url} - '\n",
    "    user_prompt+=\"please decide which of these are relevant web links  for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "        do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt+=\"Links (some might be relative links):\\nGive the output strictly in python list form\"\n",
    "    user_prompt+=\"\\n\".join(website.links)\n",
    "\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website=Website(url)\n",
    "    response=openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":system_prompt},\n",
    "            {\"role\":\"user\", \"content\": get_user_prompt(website)}\n",
    "        ],\n",
    "\n",
    "            response_format={\"type\":\"json_object\"}\n",
    "    )\n",
    "    result=response.choices[0].message.content\n",
    "    return json.loads(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectTimeout(Exception):\n",
    "    \"\"\"Custom exception for connection timeout.\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def retry(url, retries=5, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return Website(url).get_contents()  \n",
    "        except (ConnectTimeout, TimeoutError, Exception) as e:\n",
    "            print(f\"Error occurred for {url}: {e}. Attempt {attempt + 1} of {retries}.\")\n",
    "            time.sleep(delay)  \n",
    "    print(f\"Skipping {url} after {retries} failed attempts.\")\n",
    "    return f\"Failed to retrieve contents for {url}\\n\"\n",
    "\n",
    "def get_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += retry(url)  \n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    \n",
    "    key_to_check = next(iter(links), None) \n",
    "    \n",
    "    if key_to_check == 'links':\n",
    "        for link in links[\"links\"]:\n",
    "            result += f\"\\n\\n{link}\\n\"\n",
    "            result += retry(link)  \n",
    "    elif key_to_check == 'relevant_links':\n",
    "        for link in links[\"relevant_links\"]:\n",
    "            result += f\"\\n\\n{link}\\n\"\n",
    "            result += retry(link)  \n",
    "    else:\n",
    "        result += \"\\nNo relevant links found.\\n\"\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a website ( it can be company website, college club website, someone's portfolio) so be prepared \\\n",
    "and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a professional brief brochure of the website in markdown.At footer always give the contacts link of their social media handles (except phone number) if available\\n\"\n",
    "    user_prompt += get_details(url)\n",
    "    user_prompt = user_prompt[:5_000] \n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'relevant_links': ['https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/posts', 'https://huggingface.co/docs', 'https://huggingface.co/enterprise', 'https://huggingface.co/pricing', 'https://huggingface.co/deepseek-ai/DeepSeek-R1', 'https://huggingface.co/hexgrad/Kokoro-82M', 'https://huggingface.co/openbmb/MiniCPM-o-2_6', 'https://huggingface.co/spaces/hexgrad/Kokoro-TTS', 'https://huggingface.co/spaces/tencent/Hunyuan3D-2', 'https://huggingface.co/spaces/lllyasviel/iclight-v2', 'https://huggingface.co/spaces/JeffreyXiang/TRELLIS', 'https://huggingface.co/spaces/FaceOnLive/Face-Search-Online', 'https://huggingface.co/datasets/fka/awesome-chatgpt-prompts', 'https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset', 'https://huggingface.co/datasets/yale-nlp/MMVU', 'https://huggingface.co/datasets/NovaSky-AI/Sky-T1_data_17k', 'https://huggingface.co/datasets/bespokelabs/Bespoke-Stratos-17k', 'https://huggingface.co/docs/transformers', 'https://huggingface.co/docs/diffusers', 'https://huggingface.co/docs/safetensors', 'https://huggingface.co/docs/huggingface_hub', 'https://huggingface.co/docs/tokenizers', 'https://huggingface.co/docs/peft', 'https://huggingface.co/docs/transformers.js', 'https://huggingface.co/docs/timm', 'https://huggingface.co/docs/trl', 'https://huggingface.co/docs/datasets', 'https://huggingface.co/docs/text-generation-inference', 'https://huggingface.co/docs/accelerate', 'https://ui.endpoints.huggingface.co', 'https://huggingface.co/chat', 'https://huggingface.co/huggingface', 'https://huggingface.co/brand', 'https://apply.workable.com/huggingface/', 'https://huggingface.co/learn', 'https://huggingface.co/blog', 'https://discuss.huggingface.co', 'https://status.huggingface.co/', 'https://github.com/huggingface', 'https://twitter.com/huggingface', 'https://www.linkedin.com/company/huggingface/']}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face: The Future of AI, One Hug at a Time!\n",
       "\n",
       "**Welcome to Hugging Face**, where AI enthusiasts all around the globe come together to cuddle with cutting-edge models and datasets. We're not just a tech company; we're a cozy community dedicated to hugging machines (that...hopefully won't take us over)!\n",
       "\n",
       "---\n",
       "\n",
       "### üåü What We Offer:\n",
       "- **Models Galore**: Over **400k+ models** just waiting for you to give them a big ol‚Äô hug! From creating emojis to predicting the weather (okay, maybe not that), we have it all!\n",
       "- **Datasets for Days**: Want to play with **100k+ datasets**? We got 'em! (No hugs needed, just knowledge).\n",
       "- **Spaces for Creativity**: Our virtual playground hosts over **150k applications** where your imagination can run wild (just no running in the hallways, please!).\n",
       "\n",
       "---\n",
       "\n",
       "### üíº Careers at Hugging Face:\n",
       "Join our incredible team to help build the next generation of AI, while basking in the warmth of our unique company culture. We believe in:\n",
       "- **Collaboration Over Competition**: We‚Äôre here to lift each other up, and yes, occasionally share the last slice of pizza during lunch.\n",
       "- **Supportive Coworkers**: Everyone here is just one \"hug\" (or Slack message) away from giving you a helping hand!\n",
       "- **Remote Inclusivity**: Whether you want to work in comfy pajamas or business casual, we‚Äôve got your back (and your front)!\n",
       "\n",
       "---\n",
       "\n",
       "### ü§ù Who Uses Hugging Face?\n",
       "Forget about your lonely algorithms! We have an extensive lineup of **over 50,000 organizations** using Hugging Face, including giants like:\n",
       "- **Google**\n",
       "- **Amazon Web Services**\n",
       "- **Microsoft**\n",
       "- And countless others who want to show their algorithms some love!\n",
       "\n",
       "---\n",
       "\n",
       "### üöÄ Join the Hugging Face Revolution!\n",
       "Our prices start at just **$20/user/month** for teams eager to scale their AI talents‚Äîsave a dime while snuggling with the best! Plus, GPUs are available for a mere **$0.60/hour**. \n",
       "\n",
       "Sign up today and become part of our hug-tastic community, whether you're an investor eager to cash in, a curious customer, or a recruit ready to embrace an exciting career!\n",
       "\n",
       "---\n",
       "\n",
       "### üíå Stay Connected:\n",
       "Follow us for the latest updates, memes, and AI breakthroughs!\n",
       "\n",
       "- [GitHub](https://github.com/huggingface)\n",
       "- [Twitter](https://twitter.com/huggingface)\n",
       "- [LinkedIn](https://linkedin.com/company/huggingface)\n",
       "- [Discord](https://discord.gg/huggingface)\n",
       "\n",
       "---\n",
       "\n",
       "**Hugging Face**: Because who doesn't need a digital hug from an AI every now and then? ü§ó"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image depicts a landfill with various types of waste. Here‚Äôs a general classification of materials visible in the image:\\n\\n1. **Plastic**: Bags, wrappers, and other plastic items. \\n   - **Type**: Non-biodegradable, recyclable (if sorted properly).\\n\\n2. **Paper**: Pieces of paper and cardboard.\\n   - **Type**: Biodegradable, recyclable (if not contaminated).\\n\\n3. **Metal**: Possible metallic items or containers.\\n   - **Type**: Non-biodegradable, recyclable.\\n\\n4. **Organic Waste**: Various decaying organic materials.\\n   - **Type**: Biodegradable, compostable.\\n\\n5. **Textiles**: Pieces of clothing or fabric.\\n   - **Type**: Biodegradable (natural fibers), recyclable (synthetic).\\n\\nThis kind of landfill waste is mixed, containing both recyclable and non-recyclable materials, as well as biodegradable and non-biodegradable waste. Proper sorting and recycling processes can help manage such waste more efficiently.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is in this image and classify each material you see if its garbage classify what type of waste is this?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://www.treehugger.com/thmb/VG2npeTMAl7EyduCgt4QCEPGbnk=/750x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/GettyImages-139804274-571a88323df78c56403e1954.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
